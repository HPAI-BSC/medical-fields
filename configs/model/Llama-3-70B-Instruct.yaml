# https://github.com/vllm-project/vllm/blob/main/vllm/entrypoints/llm.py
name: Llama-3-70B-Instruct
vllm:
  model: "/gpfs/projects/bsc70/heka/models/${model.name}"
  tokenizer: "/gpfs/projects/bsc70/heka/models/${model.name}"
  tensor_parallel_size: 4
  trust_remote_code: True
  max_model_len: 4096
  gpu_memory_utilization: 0.75 

sampling_params:
  temperature: 0.7
  top_k: 50
  top_p: 0.9
  max_tokens: 500
  stop: ["<|eot_id|>"]