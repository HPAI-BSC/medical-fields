name: Mistral-7B-v0.1 
vllm:
  model: "/gpfs/projects/bsc70/heka/models/${model.name}"
  tokenizer: "/gpfs/projects/bsc70/heka/models/${model.name}"
  tensor_parallel_size: 2
  trust_remote_code: True
  max_model_len: 2048
  gpu_memory_utilization: 0.7 

sampling_params:
  temperature: 0.1
  top_p: 0.9
  max_tokens: 75
  stop: ["<|im_end|>", "<|endoftext|>", "<|im_start|>"]